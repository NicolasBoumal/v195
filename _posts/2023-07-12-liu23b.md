---
title: Exponential Hardness of Reinforcement Learning with Linear Function Approximation
abstract: 'A fundamental question in reinforcement learning theory is: suppose the
  optimal value functions are linear in given features, can we learn them efficiently?
  This problem’s counterpart in supervised learning, linear regression, can be solved
  both statistically and computationally efficiently. Therefore, it was quite surprising
  when a recent work \cite{kane2022computational} showed a computational-statistical
  gap for linear reinforcement learning: even though there are polynomial sample-complexity
  algorithms, unless NP = RP, there are no polynomial time algorithms for this setting.In
  this work, we build on their result to show a computational lower bound, which is
  exponential in feature dimension and horizon, for linear reinforcement learning
  under the Randomized Exponential Time Hypothesis. To prove this we build a round-based
  game where in each round the learner is searching for an unknown vector in a unit
  hypercube. The rewards in this game are chosen such that if the learner achieves
  large reward, then the learner’s actions can be used to simulate solving a variant
  of 3-SAT, where (a) each variable shows up in a bounded number of clauses (b) if
  an instance has no solutions then it also has no solutions that satisfy more than
  (1-$\epsilon$)-fraction of clauses. We use standard reductions to show this 3-SAT
  variant is approximately as hard as 3-SAT. Finally, we also show a lower bound optimized
  for horizon dependence that almost matches the best known upper bound of $\exp(\sqrt{H})$.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu23b
month: 0
tex_title: Exponential Hardness of Reinforcement Learning with Linear Function Approximation
firstpage: 1588
lastpage: 1617
page: 1588-1617
order: 1588
cycles: false
bibtex_author: Liu, Sihan and Mahajan, Gaurav and Kane, Daniel and Lovett, Shachar
  and Weisz, Gell{\'e}rt and Szepesv{\'a}ri, Csaba
author:
- given: Sihan
  family: Liu
- given: Gaurav
  family: Mahajan
- given: Daniel
  family: Kane
- given: Shachar
  family: Lovett
- given: Gellért
  family: Weisz
- given: Csaba
  family: Szepesvári
date: 2023-07-12
address: 
container-title: Proceedings of Thirty Sixth Conference on Learning Theory
volume: '195'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 12
pdf: https://proceedings.mlr.press/v195/liu23b/liu23b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
