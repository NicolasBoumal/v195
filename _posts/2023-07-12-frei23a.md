---
title: Benign Overfitting in Linear Classifiers and Leaky ReLU Networks from KKT Conditions
  for Margin Maximization
abstract: 'Linear classifiers and leaky ReLU networks trained by gradient flow on
  the logistic loss have an implicit bias towards solutions which satisfy the Karush–Kuhn–Tucker
  (KKT) conditions for margin maximization. In this work we establish a number of
  settings where the satisfaction of these KKT conditions implies benign overfitting
  in linear classifiers and in two-layer leaky ReLU networks: the estimators interpolate
  noisy training data and simultaneously generalize well to test data. The settings
  include variants of the noisy class-conditional Gaussians considered in previous
  work as well as new distributional settings where benign overfitting has not been
  previously observed. The key ingredient to our proof is the observation that when
  the training data is nearly-orthogonal, both linear classifiers and leaky ReLU networks
  satisfying the KKT conditions for their respective margin maximization problems
  behave like a weighted average of the training examples.'
section: Original Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: frei23a
month: 0
tex_title: Benign Overfitting in Linear Classifiers and Leaky ReLU Networks from KKT
  Conditions for Margin Maximization
firstpage: 3173
lastpage: 3228
page: 3173-3228
order: 3173
cycles: false
bibtex_author: Frei, Spencer and Vardi, Gal and Bartlett, Peter and Srebro, Nathan
author:
- given: Spencer
  family: Frei
- given: Gal
  family: Vardi
- given: Peter
  family: Bartlett
- given: Nathan
  family: Srebro
date: 2023-07-12
address: 
container-title: Proceedings of Thirty Sixth Conference on Learning Theory
volume: '195'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 12
pdf: https://proceedings.mlr.press/v195/frei23a/frei23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
