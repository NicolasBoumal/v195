---
title: Improved Discretization Analysis for Underdamped Langevin Monte Carlo
abstract: 'Underdamped Langevin Monte Carlo (ULMC) is an algorithm used to sample
  from unnormalized densities by leveraging the momentum of a particle moving in a
  potential well. We provide a novel analysis of ULMC, motivated by two central questions:
  (1) Can we obtain improved sampling guarantees beyond strong log-concavity? (2)
  Can we achieve acceleration for sampling?For (1), prior results for ULMC only hold
  under a log-Sobolev inequality together with a restrictive Hessian smoothness condition.
  Here, we relax these assumptions by removing the Hessian smoothness condition and
  by considering distributions satisfying a Poincare inequality. Our analysis achieves
  the state of art dimension dependence, and is also flexible enough to handle weakly
  smooth potentials. As a byproduct, we also obtain the first KL divergence guarantees
  for ULMC without Hessian smoothness under strong log-concavity, which is based on
  a new result on the log-Sobolev constant along the underdamped Langevin diffusion.For
  (2), the recent breakthrough of Cao, Lu, and Wang (2020) established the first accelerated
  result for sampling in continuous time via PDE methods. Our discretization analysis
  translates their result into an algorithmic guarantee, which indeed enjoys better
  condition number dependence than prior works on ULMC, although we leave open the
  question of full acceleration in discrete time.Both (1) and (2) necessitate Renyi
  discretization bounds, which are more challenging than the typically used Wasserstein
  coupling arguments. We address this using a flexible discretization analysis based
  on Girsanovâ€™s theorem that easily extends to more general settings. '
section: Original Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang23a
month: 0
tex_title: Improved Discretization Analysis for Underdamped Langevin Monte Carlo
firstpage: 36
lastpage: 71
page: 36-71
order: 36
cycles: false
bibtex_author: Zhang, Shunshi and Chewi, Sinho and Li, Mufan and Balasubramanian,
  Krishna and Erdogdu, Murat A.
author:
- given: Shunshi
  family: Zhang
- given: Sinho
  family: Chewi
- given: Mufan
  family: Li
- given: Krishna
  family: Balasubramanian
- given: Murat A.
  family: Erdogdu
date: 2023-07-12
address: 
container-title: Proceedings of Thirty Sixth Conference on Learning Theory
volume: '195'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 12
pdf: https://proceedings.mlr.press/v195/zhang23a/zhang23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
