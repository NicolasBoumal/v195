---
title: Intrinsic dimensionality and generalization properties of the R-norm inductive
  bias
abstract: We study the structural and statistical properties of R-norm minimizing
  interpolants of datasets labeled by specific target functions. The R-norm is the
  basis of an inductive bias for two-layer neural networks, recently introduced to
  capture the functional effect of controlling the size of network weights, independently
  of the network width. We find that these interpolants are intrinsically multivariate
  functions, even when there are ridge functions that fit the data, and also that
  the R-norm inductive bias is not sufficient for achieving statistically optimal
  generalization for certain learning problems. Altogether, these results shed new
  light on an inductive bias that is connected to practical neural network training.
section: Original Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ardeshir23a
month: 0
tex_title: Intrinsic dimensionality and generalization properties of the R-norm inductive
  bias
firstpage: 3264
lastpage: 3303
page: 3264-3303
order: 3264
cycles: false
bibtex_author: Ardeshir, Navid and Hsu, Daniel J. and Sanford, Clayton H.
author:
- given: Navid
  family: Ardeshir
- given: Daniel J.
  family: Hsu
- given: Clayton H.
  family: Sanford
date: 2023-07-12
address: 
container-title: Proceedings of Thirty Sixth Conference on Learning Theory
volume: '195'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 12
pdf: https://proceedings.mlr.press/v195/ardeshir23a/ardeshir23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
