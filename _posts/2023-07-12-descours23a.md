---
title: Law of Large Numbers for Bayesian two-layer Neural Network trained with Variational
  Inference
abstract: 'We provide a rigorous analysis of training by variational inference (VI)
  of Bayesian neural networks in the two-layer and infinite-width case. We consider
  a regression problem with a regularized evidence lower bound (ELBO) which is decomposed
  into the expected log-likelihood of the data and the Kullback-Leibler (KL) divergence
  between the a priori distribution and the variational posterior. With an appropriate
  weighting of the KL, we prove a law of large numbers for three different training
  schemes: (i) the idealized case with exact estimation of a multiple Gaussian integral
  from the reparametrization trick, (ii) a minibatch scheme using Monte Carlo sampling,
  commonly known as Bayes by Backprop, and (iii) a new and computationally cheaper
  algorithm which we introduce as Minimal VI. An important result is that all methods
  converge to the same mean-field limit. Finally, we illustrate our results numerically
  and discuss the need for the derivation of a central limit theorem.'
section: Original Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: descours23a
month: 0
tex_title: Law of Large Numbers for Bayesian two-layer Neural Network trained with
  Variational Inference
firstpage: 4657
lastpage: 4695
page: 4657-4695
order: 4657
cycles: false
bibtex_author: Descours, Arnaud and Huix, Tom and Guillin, Arnaud and Michel, Manon
  and Moulines, {\'E}ric and Nectoux, Boris
author:
- given: Arnaud
  family: Descours
- given: Tom
  family: Huix
- given: Arnaud
  family: Guillin
- given: Manon
  family: Michel
- given: Ã‰ric
  family: Moulines
- given: Boris
  family: Nectoux
date: 2023-07-12
address: 
container-title: Proceedings of Thirty Sixth Conference on Learning Theory
volume: '195'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 12
pdf: https://proceedings.mlr.press/v195/descours23a/descours23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
