---
title: Kernelized Diffusion Maps
abstract: Spectral clustering and diffusion maps are celebrated dimensionality reduction
  algorithms built on eigen-elements related to the diffusive structure of the data.
  The core of these procedures is the approximation of a Laplacian through a graph
  kernel approach, however this local average construction is known to be cursed by
  the high-dimension $d$. In this article, we build a different estimator of the Laplacian,
  via a reproducing kernel Hilbert spaces method, which adapts naturally to the regularity
  of the problem. We provide non-asymptotic statistical rates proving that the kernel
  estimator we build can circumvent the curse of dimensionality. Finally we discuss
  techniques (Nystr√∂m subsampling, Fourier features) that enable to reduce the computational
  cost of the estimator while not degrading its overall performance.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: pillaud-vivien23a
month: 0
tex_title: Kernelized Diffusion Maps
firstpage: 1
lastpage: 24
page: 1-24
order: 1
cycles: false
bibtex_author: Pillaud-Vivien, Loucas and Bach, Francis
author:
- given: Loucas
  family: Pillaud-Vivien
- given: Francis
  family: Bach
date: 2023-07-12
address: 
container-title: Proceedings of Thirty Sixth Conference on Learning Theory
volume: '195'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 12
pdf: https://proceedings.mlr.press/v195/pillaud-vivien23a/pillaud-vivien23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
