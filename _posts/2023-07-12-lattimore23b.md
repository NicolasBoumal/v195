---
title: A Lower Bound for Linear and Kernel Regression with Adaptive Covariates
abstract: We prove that the continuous time version of the concentration bounds by
  Abbasi-Yadkori et al. (2011) for adaptive linear regression cannot be improved in
  general, showing that there can be a significant price for sequential design. This
  resolves the continuous time version of the COLT open problem by Vakili et al. (2021b)
  on confidence intervals for kernel regression with sequential designs. Experimental
  evidence suggests that improved confidence bounds are also not possible in discrete
  time.
section: Original Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lattimore23b
month: 0
tex_title: A Lower Bound for Linear and Kernel Regression with Adaptive Covariates
firstpage: 2095
lastpage: 2113
page: 2095-2113
order: 2095
cycles: false
bibtex_author: Lattimore, Tor
author:
- given: Tor
  family: Lattimore
date: 2023-07-12
address: 
container-title: Proceedings of Thirty Sixth Conference on Learning Theory
volume: '195'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 12
pdf: https://proceedings.mlr.press/v195/lattimore23b/lattimore23b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
